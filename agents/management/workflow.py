"""
LangGraph Command ê°ì²´ í™œìš© Management ì›Œí¬í”Œë¡œìš°

Command ê°ì²´ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ì™€ ì œì–´ í”Œë¡œìš°ë¥¼ í†µí•©í•œ 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°:
1. ì´ˆê¸° ê²€ìƒ‰ â†’ ë™ì  ë¼ìš°íŒ… â†’ 2. í‚¤ì›Œë“œ ì¶”ì¶œ â†’ ì¡°ê±´ë¶€ ë¼ìš°íŒ… 
â†’ 3. ì„¸ë¶€ ê²€ìƒ‰ â†’ ê²°ê³¼ ê¸°ë°˜ ë¼ìš°íŒ… â†’ 4. ì´ìŠˆ ë¶„ì„ â†’ ì‹¬ê°ë„ë³„ ë¼ìš°íŒ…

ì—ëŸ¬ ë°œìƒ ì‹œ ìë™ ë³µêµ¬ ë° ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""

from typing import Dict, Any, Optional, Literal
from langgraph.graph import StateGraph, END, START

from agents.management.modules.state import ManagementState
from agents.management.modules.nodes import (
    initial_search_node,
    keyword_extraction_node,
    detailed_search_node,
    issue_analysis_node,
    retry_initial_search_node,
    retry_keyword_extraction_node,
    get_node_execution_summary
)
from agents.management.modules.utils import (
    validate_query,
    validate_intermediate_results,
    get_required_data
)
from agents.management.modules.models import (
    TavilySearchError,
    KeywordExtractionError,
    IssueAnalysisError,
    LLMResponseError
)


def prepare_initial_state(query: str) -> ManagementState:
    """
    ì´ˆê¸° ìƒíƒœ ì¤€ë¹„ (ì…ë ¥ ê²€ì¦ í¬í•¨)
    
    Args:
        query: ê²€ìƒ‰í•  ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
        
    Returns:
        ManagementState: ì´ˆê¸°í™”ëœ ìƒíƒœ ê°ì²´
    """
    print(f"\nğŸš€ === Management ì›Œí¬í”Œë¡œìš° ì‹œì‘ ===")
    print(f"ğŸ“ ê²€ìƒ‰ ëŒ€ìƒ: '{query}'")
    
    # ì…ë ¥ ê²€ì¦
    if not validate_query(query):
        print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¿¼ë¦¬ì…ë‹ˆë‹¤: '{query}'")
        return {
            "query": query,
            "initial_search_results": None,
            "extracted_keywords": None,
            "detailed_search_results": None,
            "analyzed_issues": None,
            "response": [],
            "error_messages": [f"ìœ íš¨í•˜ì§€ ì•Šì€ ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'"]
        }
    
    # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
    initial_state: ManagementState = {
        "query": query,
        "initial_search_results": None,
        "extracted_keywords": None,
        "detailed_search_results": None,
        "analyzed_issues": None,
        "response": [],
        "error_messages": []
    }
    
    print(f"âœ… ì´ˆê¸° ìƒíƒœ ì¤€ë¹„ ì™„ë£Œ")
    return initial_state


# ============================================================================
# íŠ¹ìˆ˜ ì²˜ë¦¬ ë…¸ë“œë“¤ (Command ê°ì²´ í™œìš©)
# ============================================================================

def fallback_keywords_node(state: ManagementState) -> ManagementState:
    """
    ê¸°ë³¸ í‚¤ì›Œë“œ ì œê³µ ë…¸ë“œ (ì•„ì´ìœ  ê´€ë ¨ ê¸°ë³¸ í‚¤ì›Œë“œ)
    """
    print("\nğŸ”§ === ê¸°ë³¸ í‚¤ì›Œë“œ ì œê³µ ===")
    
    # ì•„ì´ìœ  ê´€ë ¨ ê¸°ë³¸ í‚¤ì›Œë“œ ì„¸íŠ¸
    default_keywords = [
        "ìŒì•…í™œë™", "ë“œë¼ë§ˆ", "ì˜í™”", "ê´‘ê³ ", "íŒ¬ë¯¸íŒ…", 
        "ì•¨ë²”", "ì½˜ì„œíŠ¸", "ì†Œì…œë¯¸ë””ì–´", "ë°œì–¸", "í–‰ë™"
    ]
    
    # ê¸°ì¡´ í‚¤ì›Œë“œì™€ ë³‘í•©
    existing_keywords = state.get("extracted_keywords", [])
    if existing_keywords:
        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ë³‘í•©
        combined = list(set(existing_keywords + default_keywords))
        print(f"ğŸ”— ê¸°ì¡´ í‚¤ì›Œë“œì™€ ë³‘í•©: {len(existing_keywords)} + {len(default_keywords)} â†’ {len(combined)}ê°œ")
    else:
        combined = default_keywords
        print(f"ğŸ“ ê¸°ë³¸ í‚¤ì›Œë“œë§Œ ì‚¬ìš©: {len(combined)}ê°œ")
    
    print(f"âœ… ìµœì¢… í‚¤ì›Œë“œ: {', '.join(combined)}")
    
    state["extracted_keywords"] = combined
    return state


def use_default_keywords_node(state: ManagementState) -> ManagementState:
    """
    ê¸°ë³¸ í‚¤ì›Œë“œ ê°•ì œ ì‚¬ìš© ë…¸ë“œ (í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ)
    """
    print("\nğŸ”§ === ê¸°ë³¸ í‚¤ì›Œë“œ ê°•ì œ ì‚¬ìš© ===")
    
    # ì—„ì„ ëœ ì•„ì´ìœ  ê´€ë ¨ í‚¤ì›Œë“œ
    default_keywords = ["ì•„ì´ìœ ", "ì´ì§€ì€", "ìŒì•…", "ë“œë¼ë§ˆ", "ê°€ìˆ˜", "ë°°ìš°"]
    
    print(f"ğŸ“ ê°•ì œ í‚¤ì›Œë“œ ì ìš©: {', '.join(default_keywords)}")
    state["extracted_keywords"] = default_keywords
    
    return state


def escalate_issues_node(state: ManagementState) -> ManagementState:
    """
    ì‹¬ê°í•œ ì´ìŠˆ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì²˜ë¦¬ ë…¸ë“œ
    """
    print("\nğŸš¨ === ì‹¬ê°í•œ ì´ìŠˆ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ===")
    
    analyzed_issues = state.get("analyzed_issues", [])
    high_severity_issues = [
        issue for issue in analyzed_issues 
        if issue.is_issue and issue.severity_level >= 3
    ]
    
    print(f"ğŸ”¥ ì‹¬ê°í•œ ì´ìŠˆ {len(high_severity_issues)}ê°œ ê°ì§€")
    
    # ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì •ë³´ ì¶”ê°€
    escalation_info = {
        "escalation_triggered": True,
        "high_severity_count": len(high_severity_issues),
        "escalation_timestamp": "í˜„ì¬ì‹œê°„",  # ì‹¤ì œë¡œëŠ” datetime.now()
        "requires_immediate_attention": True
    }
    
    state["escalation_info"] = escalation_info
    print(f"âš¡ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì²˜ë¦¬ ì™„ë£Œ")
    
    return state


def detailed_analysis_node(state: ManagementState) -> ManagementState:
    """
    ë³µì¡í•œ ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„ ë…¸ë“œ
    """
    print("\nğŸ” === ë³µì¡í•œ ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„ ===")
    
    analyzed_issues = state.get("analyzed_issues", [])
    failed_rate = state.get("failed_analysis_rate", 0.0)
    
    print(f"ğŸ“Š ì‹¤íŒ¨ìœ¨: {failed_rate:.2%}")
    print(f"ğŸ” ì¶”ê°€ ë¶„ì„ ì‹œì‘...")
    
    # ì¶”ê°€ ë¶„ì„ ì •ë³´
    detailed_info = {
        "detailed_analysis_triggered": True,
        "complexity_score": failed_rate,
        "additional_analysis_performed": True,
        "analysis_confidence": "medium" if failed_rate > 0.5 else "high"
    }
    
    state["detailed_analysis_info"] = detailed_info
    print(f"âœ… ìƒì„¸ ë¶„ì„ ì™„ë£Œ")
    
    return state


def skip_to_finalize_node(state: ManagementState) -> ManagementState:
    """
    ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡±ìœ¼ë¡œ ì¡°ê¸° ë§ˆë¬´ë¦¬ ë…¸ë“œ
    """
    print("\nâ­ï¸ === ì¡°ê¸° ë§ˆë¬´ë¦¬ ì²˜ë¦¬ ===")
    
    # ë¹ˆ ê²°ê³¼ë¡œ ì„¤ì •
    state["analyzed_issues"] = []
    state["alert_level"] = "insufficient_data"
    
    warning_msg = "ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ì—¬ ì´ìŠˆ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    state["error_messages"] = state.get("error_messages", []) + [warning_msg]
    
    print(f"âš ï¸ {warning_msg}")
    return state


def parallel_search_node(state: ManagementState) -> ManagementState:
    """
    ë³‘ë ¬ ê²€ìƒ‰ ì²˜ë¦¬ ë…¸ë“œ (ë‹¤ëŸ‰ í‚¤ì›Œë“œìš©)
    """
    print("\nğŸš€ === ë³‘ë ¬ ê²€ìƒ‰ ì²˜ë¦¬ ===")
    
    keywords = state.get("pending_keywords", [])
    print(f"ğŸ” ë³‘ë ¬ ì²˜ë¦¬ ëŒ€ìƒ: {len(keywords)}ê°œ í‚¤ì›Œë“œ")
    
    # ì‹¤ì œë¡œëŠ” ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„ (ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜)
    # ì˜ˆ: concurrent.futures.ThreadPoolExecutor ì‚¬ìš©
    
    # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
    state["detailed_search_results"] = []  # ì‹¤ì œë¡œëŠ” ë³‘ë ¬ ê²€ìƒ‰ ê²°ê³¼
    state["parallel_processing_completed"] = True
    
    print(f"âš¡ ë³‘ë ¬ ê²€ìƒ‰ ì™„ë£Œ")
    return state


def finalize_node(state: ManagementState) -> ManagementState:
    """
    ì›Œí¬í”Œë¡œìš° ìµœì¢… ë§ˆë¬´ë¦¬ ë…¸ë“œ - ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    """
    print("\nğŸ¯ === ì›Œí¬í”Œë¡œìš° ìµœì¢… ë§ˆë¬´ë¦¬ ===")
    
    # 1. ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘
    query = state.get("query", "")
    initial_results = state.get("initial_search_results", [])
    keywords = state.get("extracted_keywords", [])
    detailed_results = state.get("detailed_search_results", [])
    analyzed_issues = state.get("analyzed_issues", [])
    
    # 2. ì´ìŠˆ ë¶„ì„ ê²°ê³¼ ì •ë¦¬
    real_issues = [issue for issue in analyzed_issues if issue.is_issue]
    total_articles = len(initial_results) + len(detailed_results)
    
    # ì‹¬ê°ë„ë³„ ë¶„í¬
    severity_dist = {}
    category_dist = {}
    high_risk_issues = []
    
    for issue in real_issues:
        severity = issue.severity_level
        severity_dist[severity] = severity_dist.get(severity, 0) + 1
        
        category = issue.issue_category  
        category_dist[category] = category_dist.get(category, 0) + 1
        
        if severity >= 3:
            high_risk_issues.append(issue)
    
    # 3. ìœ„í—˜ë„ í‰ê°€
    if len(high_risk_issues) >= 2:
        risk_level = "HIGH"
        risk_color = "ğŸ”´"
    elif len(real_issues) >= 3:
        risk_level = "MEDIUM" 
        risk_color = "ğŸŸ¡"
    elif len(real_issues) >= 1:
        risk_level = "LOW"
        risk_color = "ğŸŸ¢"
    else:
        risk_level = "MINIMAL"
        risk_color = "âœ…"
    
    # 4. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    final_report = {
        "executive_summary": {
            "target": query,
            "analysis_date": "2024-12-28",
            "total_articles_analyzed": total_articles,
            "issues_found": len(real_issues),
            "risk_level": risk_level,
            "risk_assessment": f"{risk_color} {risk_level} ìœ„í—˜ë„"
        },
        
        "issue_analysis": {
            "total_issues": len(real_issues),
            "high_severity_issues": len(high_risk_issues),
            "severity_distribution": severity_dist,
            "category_distribution": category_dist,
            "issue_details": [
                {
                    "title": issue.original_result.title[:100],
                    "category": issue.issue_category,
                    "severity": issue.severity_level,
                    "summary": issue.summary,
                    "confidence": issue.confidence_score
                }
                for issue in real_issues[:5]  # ìƒìœ„ 5ê°œë§Œ
            ]
        },
        
        "keyword_trends": {
            "extracted_keywords": keywords,
            "trending_topics": keywords[:3] if keywords else [],
            "search_coverage": f"{len(keywords)}ê°œ í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ"
        },
        
        "recommendations": {
            "immediate_actions": [],
            "monitoring_points": [],
            "long_term_strategy": []
        }
    }
    
    # 5. ìœ„í—˜ë„ë³„ ì¶”ì²œ ì•¡ì…˜ ìƒì„±
    if risk_level == "HIGH":
        final_report["recommendations"]["immediate_actions"] = [
            "ğŸš¨ ì¦‰ì‹œ ìœ„ê¸°ê´€ë¦¬íŒ€ ì†Œì§‘",
            "ğŸ“¢ ê³µì‹ ì…ì¥ ë°œí‘œ ê²€í† ",
            "ğŸ“± ì†Œì…œë¯¸ë””ì–´ ëª¨ë‹ˆí„°ë§ ê°•í™”"
        ]
    elif risk_level == "MEDIUM":
        final_report["recommendations"]["immediate_actions"] = [
            "âš ï¸ ìƒí™© ëª¨ë‹ˆí„°ë§ ê°•í™”", 
            "ğŸ“‹ ëŒ€ì‘ ì‹œë‚˜ë¦¬ì˜¤ ì¤€ë¹„",
            "ğŸ¤ íŒ¬ ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ ê°•í™”"
        ]
    else:
        final_report["recommendations"]["immediate_actions"] = [
            "âœ… í˜„ì¬ ìƒí™© ì–‘í˜¸",
            "ğŸ“Š ì •ê¸° ëª¨ë‹ˆí„°ë§ ì§€ì†",
            "ğŸ’ª ê¸ì •ì  ì½˜í…ì¸  ê°•í™”"
        ]
    
    # ê³µí†µ ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
    final_report["recommendations"]["monitoring_points"] = [
        f"ğŸ” '{keywords[0] if keywords else query}' í‚¤ì›Œë“œ ì§€ì† ëª¨ë‹ˆí„°ë§",
        "ğŸ“ˆ ì—¬ë¡  ë³€í™” ì¶”ì´ ê´€ì°°",
        "ğŸ“° ì£¼ìš” ì–¸ë¡  ë³´ë„ ì¶”ì "
    ]
    
    # 6. ì‹¤í–‰ ë©”íƒ€ë°ì´í„°
    summary = get_node_execution_summary(state)
    total_steps = 4
    completed_steps = sum([
        1 if initial_results else 0,
        1 if keywords else 0,
        1 if detailed_results is not None else 0,
        1 if analyzed_issues is not None else 0
    ])
    success_rate = (completed_steps / total_steps) * 100
    
    final_info = {
        "workflow_completed": True,
        "success_rate": success_rate,
        "completed_steps": completed_steps,
        "total_steps": total_steps,
        "execution_summary": summary
    }
    
    # 7. ìƒíƒœ ì—…ë°ì´íŠ¸
    state["final_report"] = final_report
    state["final_info"] = final_info
    
    # 8. ì‚¬ìš©ì ì¹œí™”ì  ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ¯ === {query} ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ===")
    print(f"ğŸ“Š ë¶„ì„ ê¸°ì‚¬ ìˆ˜: {total_articles}ê°œ")
    print(f"ğŸš¨ ë°œê²¬ëœ ì´ìŠˆ: {len(real_issues)}ê°œ")
    print(f"{risk_color} ìœ„í—˜ë„: {risk_level}")
    
    if real_issues:
        print(f"\nğŸ“‹ ì£¼ìš” ì´ìŠˆ:")
        for i, issue in enumerate(real_issues[:3], 1):
            print(f"   {i}. [{issue.issue_category}] {issue.summary[:50]}... (ì‹¬ê°ë„: {issue.severity_level})")
    
    if keywords:
        print(f"\nğŸ” íŠ¸ë Œë”© í‚¤ì›Œë“œ: {', '.join(keywords[:5])}")
    
    print(f"\nğŸ’¡ ì¦‰ì‹œ ì•¡ì…˜:")
    for action in final_report["recommendations"]["immediate_actions"]:
        print(f"   â€¢ {action}")
    
    print(f"\nâœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ (ì„±ê³µë¥ : {success_rate:.1f}%)")
    
    return state


# ============================================================================
# ì›Œí¬í”Œë¡œìš° êµ¬ì„± ë° ì‹¤í–‰
# ============================================================================

def create_management_workflow() -> StateGraph:
    """
    Command ê°ì²´ ê¸°ë°˜ Management ì›Œí¬í”Œë¡œìš° ìƒì„±
    
    Returns:
        StateGraph: ì»´íŒŒì¼ ì¤€ë¹„ëœ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„
    """
    print("\nğŸ”§ === Command ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° êµ¬ì„± ===")
    
    # StateGraph ì´ˆê¸°í™”
    workflow = StateGraph(ManagementState)
    
    # ì£¼ìš” ë…¸ë“œ ì¶”ê°€ (Command ê°ì²´ ë°˜í™˜)
    workflow.add_node("initial_search", initial_search_node)
    workflow.add_node("keyword_extraction", keyword_extraction_node) 
    workflow.add_node("detailed_search", detailed_search_node)
    workflow.add_node("issue_analysis", issue_analysis_node)
    
    # ì—ëŸ¬ ë³µêµ¬ ë…¸ë“œ ì¶”ê°€
    workflow.add_node("retry_initial_search", retry_initial_search_node)
    workflow.add_node("retry_keyword_extraction", retry_keyword_extraction_node)
    
    # íŠ¹ìˆ˜ ì²˜ë¦¬ ë…¸ë“œ ì¶”ê°€ (ì¼ë°˜ í•¨ìˆ˜)
    workflow.add_node("fallback_keywords", fallback_keywords_node)
    workflow.add_node("use_default_keywords", use_default_keywords_node)
    workflow.add_node("escalate_issues", escalate_issues_node)
    workflow.add_node("detailed_analysis", detailed_analysis_node)
    workflow.add_node("skip_to_finalize", skip_to_finalize_node)
    workflow.add_node("parallel_search", parallel_search_node)
    workflow.add_node("finalize", finalize_node)
    
    # ì‹œì‘ì  ì„¤ì • (Command ê°ì²´ê°€ ìë™ ë¼ìš°íŒ…í•˜ë¯€ë¡œ ë‹¨ìˆœí™”)
    workflow.add_edge(START, "initial_search")
    
    # ì¼ë°˜ ë…¸ë“œë“¤ì€ finalizeë¡œ ì—°ê²° (Command ê°ì²´ê°€ ì§ì ‘ ë¼ìš°íŒ…í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
    workflow.add_edge("fallback_keywords", "detailed_search")
    workflow.add_edge("use_default_keywords", "detailed_search")
    workflow.add_edge("escalate_issues", "finalize")
    workflow.add_edge("detailed_analysis", "finalize")
    workflow.add_edge("skip_to_finalize", "finalize")
    workflow.add_edge("parallel_search", "issue_analysis")
    workflow.add_edge("finalize", END)
    
    print(f"âœ… ì›Œí¬í”Œë¡œìš° êµ¬ì„± ì™„ë£Œ:")
    print(f"   ğŸ“Š ì´ ë…¸ë“œ ìˆ˜: 12ê°œ")
    print(f"   ğŸ”„ Command ë…¸ë“œ: 6ê°œ")
    print(f"   ğŸ› ï¸ ì¼ë°˜ ë…¸ë“œ: 6ê°œ")
    
    return workflow


def run_management_workflow(query: str, config: Optional[Dict[str, Any]] = None) -> ManagementState:
    """
    Management ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Command ê°ì²´ í™œìš©)
    
    Args:
        query: ê²€ìƒ‰í•  ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
        config: ì‹¤í–‰ ì„¤ì • (ì˜µì…˜)
        
    Returns:
        ManagementState: ì‹¤í–‰ ì™„ë£Œëœ ìµœì¢… ìƒíƒœ
    """
    try:
        print(f"\nğŸš€ === Management ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘ ===")
        print(f"ğŸ“ ê²€ìƒ‰ ëŒ€ìƒ: '{query}'")
        
        # 1. ì´ˆê¸° ìƒíƒœ ì¤€ë¹„
        initial_state = prepare_initial_state(query)
        
        # ê¸°ë³¸ ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì¡°ê¸° ë°˜í™˜
        if initial_state.get("error_messages"):
            print(f"âŒ ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨ - ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨")
            return initial_state
        
        # 2. ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ì»´íŒŒì¼
        workflow = create_management_workflow()
        compiled_workflow = workflow.compile()
        
        print(f"âœ… ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼ ì™„ë£Œ")
        
        # 3. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Command ê°ì²´ê°€ ìë™ ë¼ìš°íŒ…)
        print(f"ğŸƒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...")
        
        # ì‹¤í–‰ ì„¤ì • ì¤€ë¹„
        run_config = config or {}
        
        # LangGraph ì‹¤í–‰
        final_state = compiled_workflow.invoke(initial_state, config=run_config)
        
        # 4. ì‹¤í–‰ ê²°ê³¼ ê²€ì¦
        if not final_state:
            error_msg = "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            print(f"âŒ {error_msg}")
            
            initial_state["error_messages"] = initial_state.get("error_messages", []) + [error_msg]
            return initial_state
        
        # 5. ì‹¤í–‰ ì„±ê³µ
        success_rate = final_state.get("final_info", {}).get("success_rate", 0)
        print(f"âœ… ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ")
        print(f"ğŸ“Š ìµœì¢… ì„±ê³µë¥ : {success_rate:.1f}%")
        
        return final_state
        
    except Exception as e:
        error_msg = f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
        print(f"ğŸ’¥ {error_msg}")
        
        # ì•ˆì „í•œ ìƒíƒœ ë°˜í™˜
        if 'initial_state' in locals():
            initial_state["error_messages"] = initial_state.get("error_messages", []) + [error_msg]
            return initial_state
        else:
            # ì´ˆê¸° ìƒíƒœ ìƒì„±ë„ ì‹¤íŒ¨í•œ ê²½ìš°
            return {
                "query": query,
                "initial_search_results": None,
                "extracted_keywords": None,
                "detailed_search_results": None,
                "analyzed_issues": None,
                "response": [],
                "error_messages": [error_msg]
            }


def safe_workflow_execution(query: str, max_retries: int = 2) -> ManagementState:
    """
    ì•ˆì „í•œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ì¬ì‹œë„ í¬í•¨)
    
    Args:
        query: ê²€ìƒ‰í•  ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
    Returns:
        ManagementState: ì‹¤í–‰ ì™„ë£Œëœ ìµœì¢… ìƒíƒœ
    """
    for attempt in range(max_retries + 1):
        try:
            print(f"\nğŸ”„ === ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œë„ {attempt + 1}/{max_retries + 1} ===")
            
            result = run_management_workflow(query)
            
            # ì„±ê³µ ì—¬ë¶€ í™•ì¸
            success_rate = result.get("final_info", {}).get("success_rate", 0)
            
            if success_rate >= 50:  # 50% ì´ìƒ ì„±ê³µ ì‹œ ì¢…ë£Œ
                print(f"âœ… ì›Œí¬í”Œë¡œìš° ì„±ê³µ (ì„±ê³µë¥ : {success_rate:.1f}%)")
                return result
            elif attempt < max_retries:
                print(f"âš ï¸ ì„±ê³µë¥  ë¶€ì¡± ({success_rate:.1f}%) - ì¬ì‹œë„")
                continue
            else:
                print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ - í˜„ì¬ ê²°ê³¼ ë°˜í™˜")
                return result
                
        except Exception as e:
            error_msg = f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}"
            print(f"âŒ {error_msg}")
            
            if attempt == max_retries:
                # ìµœì¢… ì‹¤íŒ¨
                return {
                    "query": query,
                    "initial_search_results": None,
                    "extracted_keywords": None,
                    "detailed_search_results": None,
                    "analyzed_issues": None,
                    "response": [],
                    "error_messages": [error_msg]
                }
            else:
                print(f"ğŸ”„ ì¬ì‹œë„ ëŒ€ê¸° ì¤‘...")


# ============================================================================
# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„±)
# ============================================================================

def execute_management_workflow(query: str) -> ManagementState:
    """
    í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        query: ê²€ìƒ‰í•  ì¸í”Œë£¨ì–¸ì„œ ì´ë¦„
        
    Returns:
        ManagementState: ì‹¤í–‰ ì™„ë£Œëœ ìµœì¢… ìƒíƒœ
    """
    return safe_workflow_execution(query)


# ============================================================================
# LangGraph Dev ì„œë²„ë¥¼ ìœ„í•œ Export
# ============================================================================

# LangGraph dev ì„œë²„ì—ì„œ ì‚¬ìš©í•  ì»´íŒŒì¼ëœ ì›Œí¬í”Œë¡œìš°
management_workflow = create_management_workflow().compile()
