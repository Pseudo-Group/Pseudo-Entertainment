"""
03_API_specification.md ê¸°ë°˜ ì¸í”Œë£¨ì–¸ì„œ ì´ìŠˆ ë¶„ì„ì„ ìœ„í•œ ì²´ì¸(Chains) ëª¨ë“ˆ

LLMê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì´ìŠˆ ë¶„ì„ ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
JSON response_formatì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì‘ë‹µì„ ë³´ì¥í•©ë‹ˆë‹¤.
"""

import json
from typing import List

from agents.management.modules.models import (
    get_openai_model,
    SearchResult,
    IssueAnalysis,
    KeywordExtractionError,
    IssueAnalysisError,
    LLMResponseError
)
from agents.management.modules.prompts import (
    get_keyword_extraction_prompt,
    get_issue_analysis_prompt
)
from agents.management.modules.utils import (
    validate_query, 
    convert_llm_to_issue_analysis,
    clean_text_simple,
    clean_keywords_simple
)


class KeywordExtractionChain:
    """
    03_API_specification.md ì„¹ì…˜ 2.2 ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸
    JSON response_formatì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ í‚¤ì›Œë“œ ì¶”ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì²´ì¸ ì´ˆê¸°í™” - JSON ì¶œë ¥ ê°•ì œ"""
        self.model = get_openai_model(
            temperature=0.3,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
            response_format={"type": "json_object"}  # JSON ì¶œë ¥ ê°•ì œ
        )
        self.prompt = get_keyword_extraction_prompt()
        print("âœ… KeywordExtractionChain ì´ˆê¸°í™” ì™„ë£Œ (JSON mode)")
    
    def extract_keywords(
        self, 
        search_results: List[SearchResult],
        target_count: int = 8
    ) -> List[str]:
        """
        í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰ (03_API_specification.md ê¸°ë°˜)
        
        Args:
            search_results: SearchResult ê°ì²´ ëª©ë¡
            target_count: ëª©í‘œ í‚¤ì›Œë“œ ê°œìˆ˜ (ê¸°ë³¸ê°’: 8)
            
        Returns:
            List[str]: ì¶”ì¶œëœ í‚¤ì›Œë“œ ëª©ë¡
            
        Raises:
            KeywordExtractionError: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        try:
            if not search_results:
                raise KeywordExtractionError("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"ğŸ”‘ {len(search_results)}ê°œ SearchResultì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘...")
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
            combined_text = self._combine_search_results(search_results)
            
            # ì²´ì¸ ì‹¤í–‰
            chain = self.prompt | self.model
            response = chain.invoke({
                "search_results_formatted": combined_text,
                "target_count": target_count
            })
            
            # JSON ì‘ë‹µ íŒŒì‹±
            response_text = response.content if hasattr(response, 'content') else str(response)
            result_data = json.loads(response_text)
            
            keywords = result_data.get("keywords", [])
            reasoning = result_data.get("reasoning", "")
            
            # ê²°ê³¼ ê²€ì¦
            if not keywords:
                raise KeywordExtractionError("LLMì´ í‚¤ì›Œë“œë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ëª©í‘œ ê°œìˆ˜ë¡œ ì œí•œ
            keywords = keywords[:target_count]
            
            print(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: {len(keywords)}ê°œ")
            print(f"ğŸ“ ì¶”ì¶œ ê·¼ê±°: {reasoning[:100]}...")
            
            return keywords
            
        except json.JSONDecodeError as e:
            raise LLMResponseError(f"LLM JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        except KeywordExtractionError:
            # ì´ë¯¸ KeywordExtractionErrorì¸ ê²½ìš° ì¬ë°œìƒ
            raise
        except Exception as e:
            raise KeywordExtractionError(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _combine_search_results(self, search_results: List[SearchResult]) -> str:
        """SearchResult ëª©ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ê²°í•© (05_workflow_and_process.md í…ìŠ¤íŠ¸ ì •ë¦¬ ì ìš©)"""
        combined_text = ""
        for i, result in enumerate(search_results[:5], 1):  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
            combined_text += f"[ê²°ê³¼ {i}]\n"
            combined_text += f"ì œëª©: {result.title}\n"
            combined_text += f"ë‚´ìš©: {result.content[:300]}...\n"
            combined_text += f"ì¶œì²˜: {result.source}\n\n"
        
        # 05_workflow_and_process.md ì„¹ì…˜ 4.2.1 í…ìŠ¤íŠ¸ ì •ë¦¬ ì ìš©
        return clean_text_simple(combined_text, max_length=8000)


class IssueAnalysisChain:
    """
    03_API_specification.md ì„¹ì…˜ 2.2 ê¸°ë°˜ ì´ìŠˆ ë¶„ì„ ì²´ì¸
    JSON response_formatì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì´ìŠˆ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì²´ì¸ ì´ˆê¸°í™” - JSON ì¶œë ¥ ê°•ì œ"""
        self.model = get_openai_model(
            temperature=0.1,  # ë¶„ì„ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
            response_format={"type": "json_object"}  # JSON ì¶œë ¥ ê°•ì œ
        )
        self.prompt = get_issue_analysis_prompt()
        print("âœ… IssueAnalysisChain ì´ˆê¸°í™” ì™„ë£Œ (JSON mode)")
    
    def analyze_issue(self, search_result: SearchResult) -> IssueAnalysis:
        """
        ì´ìŠˆ ë¶„ì„ ì‹¤í–‰ (03_API_specification.md ê¸°ë°˜)
        
        Args:
            search_result: ë¶„ì„í•  SearchResult ê°ì²´
            
        Returns:
            IssueAnalysis: ë¶„ì„ ê²°ê³¼ ê°ì²´
            
        Raises:
            IssueAnalysisError: ì´ìŠˆ ë¶„ì„ ì‹¤íŒ¨ ì‹œ
        """
        try:
            print(f"ğŸ“Š ì´ìŠˆ ë¶„ì„ ì‹œì‘: {search_result.title[:50]}...")
            
            # ì²´ì¸ ì‹¤í–‰
            chain = self.prompt | self.model
            response = chain.invoke({
                "title": search_result.title,
                "content": search_result.content,
                "source": search_result.source,
                "published_date": search_result.published_date,
                "url": search_result.url,
                "relevance_score": search_result.relevance_score
            })
            
            # JSON ì‘ë‹µ íŒŒì‹±
            response_text = response.content if hasattr(response, 'content') else str(response)
            result_data = json.loads(response_text)
            
            # IssueAnalysis ê°ì²´ ìƒì„±
            issue_analysis = IssueAnalysis(
                original_result=search_result,
                is_issue=bool(result_data.get("is_issue", False)),
                severity_level=int(result_data.get("severity_level", 1)),
                issue_category=str(result_data.get("issue_category", "ê¸°íƒ€")),
                summary=str(result_data.get("summary", "")),
                potential_impact=str(result_data.get("potential_impact", "")),
                confidence_score=float(result_data.get("confidence_score", 0.0)),
                analysis_reasoning=str(result_data.get("reasoning", ""))
            )
            
            # ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦
            self._validate_analysis_result(issue_analysis)
            
            if issue_analysis.is_issue:
                print(f"   ğŸš¨ ì´ìŠˆ ë°œê²¬: {issue_analysis.issue_category} (ì‹¬ê°ë„: {issue_analysis.severity_level})")
            else:
                print(f"   âœ… ì´ìŠˆ ì—†ìŒ (ì‹ ë¢°ë„: {issue_analysis.confidence_score:.2f})")
            
            return issue_analysis
            
        except json.JSONDecodeError as e:
            raise LLMResponseError(f"LLM JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        except (ValueError, TypeError) as e:
            raise LLMResponseError(f"LLM ì‘ë‹µ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {e}")
        except IssueAnalysisError:
            # ì´ë¯¸ IssueAnalysisErrorì¸ ê²½ìš° ì¬ë°œìƒ
            raise
        except Exception as e:
            raise IssueAnalysisError(f"ì´ìŠˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _validate_analysis_result(self, analysis: IssueAnalysis):
        """ë¶„ì„ ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦"""
        valid_categories = ["ë°œì–¸", "í–‰ë™", "ì»¨í…ì¸ ", "ê°œì¸"]
        
        if not (1 <= analysis.severity_level <= 4):
            raise IssueAnalysisError(f"ì˜ëª»ëœ ì‹¬ê°ë„ ë“±ê¸‰: {analysis.severity_level}")
        
        if analysis.issue_category not in valid_categories:
            raise IssueAnalysisError(f"ì˜ëª»ëœ ì´ìŠˆ ì¹´í…Œê³ ë¦¬: {analysis.issue_category}")
        
        if not (0.0 <= analysis.confidence_score <= 1.0):
            raise IssueAnalysisError(f"ì˜ëª»ëœ ì‹ ë¢°ë„ ì ìˆ˜: {analysis.confidence_score}")


# ì „ì—­ ì²´ì¸ ì¸ìŠ¤í„´ìŠ¤ë“¤
_keyword_chain = None
_analysis_chain = None


def create_keyword_extraction_chain():
    """
    í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
    
    Returns:
        KeywordExtractionChain: í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸
    """
    global _keyword_chain
    if _keyword_chain is None:
        _keyword_chain = KeywordExtractionChain()
    return _keyword_chain


def create_issue_analysis_chain():
    """
    ì´ìŠˆ ë¶„ì„ì„ ìœ„í•œ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤ (ì‹±ê¸€í†¤ íŒ¨í„´)

    Returns:
        IssueAnalysisChain: ì´ìŠˆ ë¶„ì„ ì²´ì¸
    """
    global _analysis_chain
    if _analysis_chain is None:
        _analysis_chain = IssueAnalysisChain()
    return _analysis_chain


# 03_API_specification.md ì„¹ì…˜ 3.2: ì•ˆì „í•œ API í˜¸ì¶œ
def safe_keyword_extraction(search_results: List[SearchResult], target_count: int = 8) -> List[str]:
    """
    ì•ˆì „í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (05_workflow_and_process.md í‚¤ì›Œë“œ ì •ë¦¬ ì ìš©)
    
    Args:
        search_results: SearchResult ëª©ë¡
        target_count: ëª©í‘œ í‚¤ì›Œë“œ ê°œìˆ˜

    Returns:
        List[str]: í‚¤ì›Œë“œ ëª©ë¡ (ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    """
    try:
        chain = create_keyword_extraction_chain()
        raw_keywords = chain.extract_keywords(search_results, target_count)
        # 05_workflow_and_process.md ì„¹ì…˜ 4.2.2 í‚¤ì›Œë“œ ì •ë¦¬ ì ìš©
        return clean_keywords_simple(raw_keywords)
    except (KeywordExtractionError, LLMResponseError) as e:
        print(f"ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return []
    except Exception as e:
        print(f"ğŸ”‘ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []


def safe_issue_analysis(search_result: SearchResult) -> IssueAnalysis:
    """
    ì•ˆì „í•œ ì´ìŠˆ ë¶„ì„
    
    Args:
        search_result: ë¶„ì„í•  SearchResult
        
    Returns:
        IssueAnalysis: ë¶„ì„ ê²°ê³¼ (ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’)
    """
    try:
        chain = create_issue_analysis_chain()
        return chain.analyze_issue(search_result)
    except (IssueAnalysisError, LLMResponseError) as e:
        print(f"ğŸ“Š ì´ìŠˆ ë¶„ì„ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ IssueAnalysis ë°˜í™˜
        return IssueAnalysis(
            original_result=search_result,
            is_issue=False,
            severity_level=1,
            issue_category="ê¸°íƒ€",
            summary="ë¶„ì„ ì‹¤íŒ¨",
            potential_impact="ë¶„ì„í•  ìˆ˜ ì—†ìŒ",
            confidence_score=0.0,
            analysis_reasoning=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )
    except Exception as e:
        print(f"ğŸ“Š ì˜ˆìƒì¹˜ ëª»í•œ ì´ìŠˆ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return IssueAnalysis(
            original_result=search_result,
            is_issue=False,
            severity_level=1,
            issue_category="ê¸°íƒ€",
            summary="ë¶„ì„ ì‹¤íŒ¨",
            potential_impact="ë¶„ì„í•  ìˆ˜ ì—†ìŒ",
            confidence_score=0.0,
            analysis_reasoning=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
    )
